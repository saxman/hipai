{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b90d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hipai import paths\n",
    "\n",
    "from aimu.models import OllamaClient\n",
    "from aimu.tools import MCPClient\n",
    "\n",
    "# Required to allow nested event loops in Jupyter notebooks (for MCPClient)\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OllamaClient(OllamaClient.MODEL_MISTRAL_SMALL_3_2_24B)\n",
    "\n",
    "MCP_SERVERS = {\n",
    "    \"mcpServers\": {\n",
    "        \"hipai\": {\"command\": \"python\", \"args\": [str(paths.package / \"tools.py\")]},\n",
    "    }\n",
    "}\n",
    "\n",
    "mcp_client = MCPClient(MCP_SERVERS)\n",
    "model_client.mcp_client = mcp_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are the user's friend and are curious and supportive if them.\n",
    "\n",
    "Use memory tools to store and recall information about the user.\n",
    "When you learn something about the user, use the `add_memories` tool to add it to memory.\n",
    "Use the `search_memories` tool to search for information about the user that is relevant to the conversation.\n",
    "\n",
    "Determine the user's name before starting the conversation.\n",
    "\n",
    "Your name is Bruce.\n",
    "\"\"\"\n",
    "\n",
    "generate_kwargs={\n",
    "    \"temperature\": 0.15,\n",
    "    \"top_p\": 0.9,\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"repeat_penalty\": 1.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client.messages = []\n",
    "\n",
    "response = model_client.chat_streamed(\n",
    "    {\n",
    "        \"role\": model_client.system_role,\n",
    "        \"content\": SYSTEM_PROMPT,\n",
    "    },\n",
    "    tools=mcp_client.get_tools()\n",
    ")\n",
    "\n",
    "for response_part in response:\n",
    "    print(response_part, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0b948",
   "metadata": {},
   "source": [
    "## Memory Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585dc5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_client.chat_streamed(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"what is my name?\",\n",
    "    },\n",
    "    tools=mcp_client.get_tools()\n",
    ")\n",
    "\n",
    "for response_part in response:\n",
    "    print(response_part, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c890e3",
   "metadata": {},
   "source": [
    "## Memory Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424de319",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_client.chat_streamed(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I have a new job. I now work at a bakery.\",\n",
    "    },\n",
    "    tools=mcp_client.get_tools()\n",
    ")\n",
    "\n",
    "for response_part in response:\n",
    "    print(response_part, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afae971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_client.chat_streamed(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I am also studying at the University of Washington to learn how to develop AI models. I want to be a data scientist.\",\n",
    "    },\n",
    "    tools=mcp_client.get_tools()\n",
    ")\n",
    "\n",
    "for response_part in response:\n",
    "    print(response_part, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
